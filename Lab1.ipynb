{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mbusarello/Lab1-WE-THE/blob/main/Lab1.ipynb)"
      ],
      "metadata": {
        "id": "PbIilvFYebx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LAB 1**\n",
        "\n",
        "This is Google Colab, which by this point I expect you have an idea of how it's going to be used. I have provided you with several codes, most of them just need to be executed, while one is going to require your input. We'll get to that.\n",
        "\n",
        "Every block of code in Colab is called \"cell\". For now, try to run the most simple script in the world. All you have to do is click on the \"play\" button and watch the output of the code in the space below it."
      ],
      "metadata": {
        "id": "LlMcZ9HzyUad"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwVuVpdSxuFi",
        "outputId": "a2b457f3-6523-41c0-c854-dd32d161cffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, world!\n"
          ]
        }
      ],
      "source": [
        "print('Hello, world!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple, right? This is what we are going to do during this activity :)"
      ],
      "metadata": {
        "id": "oDiQRXKlMIub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing and importing libraries and repositories\n",
        "\n",
        "In order to create the graphs that you are going to need for the analysis, first we need to install all the libraries necessary, as well as getting the data. Run the next cell to do that."
      ],
      "metadata": {
        "id": "wCrjJHxDyZRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "!pip install matplotlib\n",
        "!pip install tifffile\n",
        "!pip install seaborn\n",
        "\n",
        "!git clone https://mbusarello.github.com/mbusarello/Lab1.git\n",
        "\n",
        "import os\n",
        "import rasterio as rio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as pp\n",
        "import tifffile as tf\n",
        "from osgeo import gdal"
      ],
      "metadata": {
        "id": "mdONl14Tyf8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## F-score\n",
        "\n",
        "Since that is taken care of, we can start creating some plots. First, we are plotting the F-score obtained by the first model. You can find more information about how the F-score is calculated in Canvas."
      ],
      "metadata": {
        "id": "s-QtCrPc0E3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting f-score first model\n",
        "\n",
        "file_path = '/content/data/first-model.csv'\n",
        "\n",
        "ds = pd.read_csv(file_path)\n",
        "tp1 = ds['1_tp'].sum()\n",
        "fp1 = ds['1_fp'].sum()\n",
        "fn1 = ds['1_fn'].sum()\n",
        "tn1 = ds['1_tn'].sum()\n",
        "fs1_total = {'ditches':((2*tp1) / ((2*tp1) + fp1 + fn1))}\n",
        "\n",
        "if '2_fmes' in ds.columns:\n",
        "    n_columns = ds.rename(columns={'1_fmes':'ditches','2_fmes':'natural streams'})\n",
        "    columns = n_columns[['natural streams','ditches']]\n",
        "    tp2 = ds['2_tp'].sum()\n",
        "    fp2 = ds['2_fp'].sum()\n",
        "    fn2 = ds['2_fn'].sum()\n",
        "    tn2 = ds['2_tn'].sum()\n",
        "    fs2_total = ((2*tp2) / ((2*tp2) + fp2 + fn2))\n",
        "    fs1_total['natural streams'] = fs2_total\n",
        "    H = 2\n",
        "    \n",
        "    \n",
        "\n",
        "else:\n",
        "    n_columns = ds.rename(columns={'1_fmes':'ditches'})\n",
        "    columns = n_columns[['ditches']]\n",
        "    H = 1\n",
        "\n",
        "y_axis = np.arange(H)\n",
        "n = 2\n",
        "p = 0.15\n",
        "fig, ax = pp.subplots(figsize=(5,3))\n",
        "pp.title('F-score '+file_path.split('/')[-1].split(\".\")[0])\n",
        "ax.set_axisbelow(True)\n",
        "\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        width = rect.get_width()\n",
        "        pp.text(rect.get_width()+0.045, rect.get_y()+0.45*rect.get_height(),\n",
        "                 float(\"{:.2f}\".format(width)),\n",
        "                 ha='center', va='center',fontsize='medium')\n",
        "\n",
        "meaning = pd.DataFrame(columns.mean(),columns=['mean'])\n",
        "totalfs = pd.DataFrame.from_dict(fs1_total,orient='index',columns=['total'])\n",
        "\n",
        "combined = pd.concat([meaning,totalfs],axis=1,join='inner')\n",
        "print(combined)\n",
        "\n",
        "distance = y_axis - 0.4 + (n*p)\n",
        "barb1 = ax.barh(distance,width = sorted(meaning['mean']),height=0.2,edgecolor='black',linewidth=0.8,label='mean')\n",
        "barb2 = ax.barh(0.2+distance,width = sorted(totalfs['total']),height=0.2,edgecolor='black',hatch='//',linewidth=0.8,label='total')\n",
        "\n",
        "\n",
        "autolabel(barb1)\n",
        "autolabel(barb2)\n",
        "pp.xticks(np.arange(0,1.1,0.1))\n",
        "pp.yticks(y_axis,columns)    \n",
        "ax.legend(handles=[barb1,barb2],loc='lower right') \n",
        "pp.show()"
      ],
      "metadata": {
        "id": "dZqSnuaE0FcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing the same for the second model now - don't forget to save the images! You will need them to write your paragraph comparing the models!"
      ],
      "metadata": {
        "id": "2kI1k3zf0TMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting f-score second model\n",
        "\n",
        "file_path = '/content/data/second-model.csv'\n",
        "\n",
        "ds = pd.read_csv(file_path)\n",
        "tp1 = ds['1_tp'].sum()\n",
        "fp1 = ds['1_fp'].sum()\n",
        "fn1 = ds['1_fn'].sum()\n",
        "tn1 = ds['1_tn'].sum()\n",
        "fs1_total = {'ditches':((2*tp1) / ((2*tp1) + fp1 + fn1))}\n",
        "\n",
        "if '2_fmes' in ds.columns:\n",
        "    n_columns = ds.rename(columns={'1_fmes':'ditches','2_fmes':'natural streams'})\n",
        "    columns = n_columns[['natural streams','ditches']]\n",
        "    tp2 = ds['2_tp'].sum()\n",
        "    fp2 = ds['2_fp'].sum()\n",
        "    fn2 = ds['2_fn'].sum()\n",
        "    tn2 = ds['2_tn'].sum()\n",
        "    fs2_total = ((2*tp2) / ((2*tp2) + fp2 + fn2))\n",
        "    fs1_total['natural streams'] = fs2_total\n",
        "    H = 2\n",
        "    \n",
        "    \n",
        "\n",
        "else:\n",
        "    n_columns = ds.rename(columns={'1_fmes':'ditches'})\n",
        "    columns = n_columns[['ditches']]\n",
        "    H = 1\n",
        "\n",
        "y_axis = np.arange(H)\n",
        "n = 2\n",
        "p = 0.15\n",
        "fig, ax = pp.subplots(figsize=(5,3))\n",
        "pp.title('F-score '+file_path.split('/')[-1].split(\".\")[0])\n",
        "ax.set_axisbelow(True)\n",
        "\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        width = rect.get_width()\n",
        "        pp.text(rect.get_width()+0.045, rect.get_y()+0.45*rect.get_height(),\n",
        "                 float(\"{:.2f}\".format(width)),\n",
        "                 ha='center', va='center',fontsize='medium')\n",
        "\n",
        "meaning = pd.DataFrame(columns.mean(),columns=['mean'])\n",
        "totalfs = pd.DataFrame.from_dict(fs1_total,orient='index',columns=['total'])\n",
        "\n",
        "combined = pd.concat([meaning,totalfs],axis=1,join='inner')\n",
        "print(combined)\n",
        "\n",
        "distance = y_axis - 0.4 + (n*p)\n",
        "barb1 = ax.barh(distance,width = sorted(meaning['mean']),height=0.2,edgecolor='black',linewidth=0.8,label='mean')\n",
        "barb2 = ax.barh(0.2+distance,width = sorted(totalfs['total']),height=0.2,edgecolor='black',hatch='//',linewidth=0.8,label='total')\n",
        "\n",
        "\n",
        "autolabel(barb1)\n",
        "autolabel(barb2)\n",
        "pp.xticks(np.arange(0,1.1,0.1))\n",
        "pp.yticks(y_axis,columns)    \n",
        "ax.legend(handles=[barb1,barb2],loc='lower right') \n",
        "pp.show()"
      ],
      "metadata": {
        "id": "Y3zidLF20O29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And finally, we are doing the same for the third model:"
      ],
      "metadata": {
        "id": "kfLx5f9vDuIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting f-score third model\n",
        "\n",
        "file_path = '/content/data/third-model.csv'\n",
        "\n",
        "ds = pd.read_csv(file_path)\n",
        "tp1 = ds['1_tp'].sum()\n",
        "fp1 = ds['1_fp'].sum()\n",
        "fn1 = ds['1_fn'].sum()\n",
        "tn1 = ds['1_tn'].sum()\n",
        "fs1_total = {'ditches':((2*tp1) / ((2*tp1) + fp1 + fn1))}\n",
        "\n",
        "if '2_fmes' in ds.columns:\n",
        "    n_columns = ds.rename(columns={'1_fmes':'ditches','2_fmes':'natural streams'})\n",
        "    columns = n_columns[['natural streams','ditches']]\n",
        "    tp2 = ds['2_tp'].sum()\n",
        "    fp2 = ds['2_fp'].sum()\n",
        "    fn2 = ds['2_fn'].sum()\n",
        "    tn2 = ds['2_tn'].sum()\n",
        "    fs2_total = ((2*tp2) / ((2*tp2) + fp2 + fn2))\n",
        "    fs1_total['natural streams'] = fs2_total\n",
        "    H = 2\n",
        "    \n",
        "    \n",
        "\n",
        "else:\n",
        "    n_columns = ds.rename(columns={'1_fmes':'ditches'})\n",
        "    columns = n_columns[['ditches']]\n",
        "    H = 1\n",
        "\n",
        "y_axis = np.arange(H)\n",
        "n = 2\n",
        "p = 0.15\n",
        "fig, ax = pp.subplots(figsize=(5,3))\n",
        "pp.title('F-score '+file_path.split('/')[-1].split(\".\")[0])\n",
        "ax.set_axisbelow(True)\n",
        "\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        width = rect.get_width()\n",
        "        pp.text(rect.get_width()+0.045, rect.get_y()+0.45*rect.get_height(),\n",
        "                 float(\"{:.2f}\".format(width)),\n",
        "                 ha='center', va='center',fontsize='medium')\n",
        "\n",
        "meaning = pd.DataFrame(columns.mean(),columns=['mean'])\n",
        "totalfs = pd.DataFrame.from_dict(fs1_total,orient='index',columns=['total'])\n",
        "\n",
        "combined = pd.concat([meaning,totalfs],axis=1,join='inner')\n",
        "print(combined)\n",
        "\n",
        "distance = y_axis - 0.4 + (n*p)\n",
        "barb1 = ax.barh(distance,width = sorted(meaning['mean']),height=0.2,edgecolor='black',linewidth=0.8,label='mean')\n",
        "barb2 = ax.barh(0.2+distance,width = sorted(totalfs['total']),height=0.2,edgecolor='black',hatch='//',linewidth=0.8,label='total')\n",
        "\n",
        "\n",
        "autolabel(barb1)\n",
        "autolabel(barb2)\n",
        "pp.xticks(np.arange(0,1.1,0.1))\n",
        "pp.yticks(y_axis,columns)    \n",
        "ax.legend(handles=[barb1,barb2],loc='lower right') \n",
        "pp.show()"
      ],
      "metadata": {
        "id": "G9MeBaKFDwRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing inference and real world data\n",
        "\n",
        "How would each model fare if we gave it unseen data to try to guess the location of ditches? We can find that out using the next cell. 3 chips from the same location but from different topographic indices are used to infer the location (since this is what differs one model to another). The results are plotted below with the correct answer. The correct answer was previously manually verified."
      ],
      "metadata": {
        "id": "e1nA3MAj0rg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svf = tf.imread(\"data/inference/svf/18H007_73325_8825_25_0060.tif\")\n",
        "slope = tf.imread(\"data/inference/slope/18H007_73325_8825_25_0060.tif\")\n",
        "hpmf = tf.imread(\"data/inference/hpmf/18H007_73325_8825_25_0060.tif\")\n",
        "answer = tf.imread(\"data/answer/18H007_73325_8825_25_0060.tif\")\n",
        "\n",
        "f, axarr = pp.subplots(1,2)\n",
        "axarr[0].set_title('first-model')\n",
        "axarr[0].imshow(hpmf)\n",
        "\n",
        "axarr[1].set_title('second-model')\n",
        "axarr[1].imshow(slope)\n",
        "\n",
        "f, axarr = pp.subplots(1,2)\n",
        "axarr[0].set_title('third-model')\n",
        "axarr[0].imshow(svf)\n",
        "\n",
        "axarr[1].set_title('answer')\n",
        "axarr[1].imshow(answer)"
      ],
      "metadata": {
        "id": "scrA37rY004L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix\n",
        "\n",
        "You can find more information about how the confusion matrix is calculated in Canvas. The code below is used to create the Confusion Matrix for the first model. To create one for the second and third models, you need to change the name in the inference_result variable. To do that, you have to add a # and remove a #, as demonstrated in the video."
      ],
      "metadata": {
        "id": "NMHvJHhw0kwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#inference_result = \"data/inference/hpmf/18H007_73325_8825_25_0060.tif\"\n",
        "inference_result = \"data/inference/slope/18H007_73325_8825_25_0060.tif\"\n",
        "inference_result = \"data/inference/svf/18H007_73325_8825_25_0060.tif\"\n",
        "answer = 'data/answer/18H007_73325_8825_25_0060.tif' \n",
        "\n",
        "list_inf = []\n",
        "list_inf_r = []\n",
        "list_facit = []\n",
        "list_inf_r = []\n",
        "\n",
        "zo = 0 #0 predicted as 1\n",
        "oz = 0 #1 predicted as 0 \n",
        "zz = 0 #0 predicted as 0\n",
        "oo = 0 #1 predicted as 1\n",
        "\n",
        "f_tif = rio.open(answer)\n",
        "f_r = f_tif.read(1)\n",
        "\n",
        "i_tif = rio.open(inference_result)\n",
        "i_r = i_tif.read(1)\n",
        "\n",
        "inference = i_r.flatten()\n",
        "facit = f_r.flatten()\n",
        "\n",
        "f_tif.close()\n",
        "i_tif.close()\n",
        "\n",
        "comparison = list(x for x, (xf,xi) in enumerate(zip(facit,inference))\n",
        "     if xf != xi)\n",
        "\n",
        "for b in comparison:\n",
        "    list_inf.append(inference[b])\n",
        "    list_facit.append(facit[b])\n",
        "\n",
        "#confusion matrix values\n",
        "for value, (vf,vi) in enumerate(zip(facit,inference)):\n",
        "    if vf == 0:\n",
        "        if vi == 1:\n",
        "            zo = zo + 1\n",
        "        if vi == 0:\n",
        "            zz = zz + 1\n",
        "\n",
        "    if vf == 1:\n",
        "        if vi == 0:\n",
        "            oz = oz + 1\n",
        "        if vi == 1:\n",
        "            oo = oz + 1\n",
        "\n",
        "\n",
        "nodata_r = zz\n",
        "ditches_r = oo\n",
        "\n",
        "zero_as_one = zo\n",
        "one_as_zero = oz\n",
        "\n",
        "nd = [nodata_r,zero_as_one]\n",
        "dt = [one_as_zero,ditches_r]\n",
        "\n",
        "fdsArr = np.array([nd,dt])\n",
        "\n",
        "df_cm = pd.DataFrame(fdsArr, index=['empty','ditches'],columns=['empty','ditches'])\n",
        "\n",
        "fig,ax = pp.subplots(figsize=(10,7))\n",
        "sn.set(font_scale=2)\n",
        "ax.set_title(inference_result.split('/')[-2],fontsize=28)\n",
        "ax.tick_params(labelsize=18)\n",
        "sn.heatmap(df_cm,annot=True,cmap=\"viridis\",fmt='g',cbar=False,square=True)\n",
        "pp.ylabel('True label',fontsize=24)\n",
        "pp.xlabel('Predicted label',fontsize=24)\n",
        "pp.show()"
      ],
      "metadata": {
        "id": "DuBmntfn0jlS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}